{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGBM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFVIDyBFAa+axI9dDg4GNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeandroCoelhos/estudos_datascience/blob/main/LGBM/LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MUkutTAtcs3n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vantagens do LGBM\n",
        "\n",
        "Otimiza√ß√£o em velocidade e uso de mem√≥ria\n",
        "\n",
        "Muitas ferramentas de boosting usam algoritmos baseados em pr√©-ordena√ß√£o [2, 3] (por exemplo, algoritmo padr√£o em xgboost) para aprendizado de √°rvores de decis√£o. √â uma solu√ß√£o simples, mas n√£o f√°cil de otimizar.\n",
        "\n",
        "O LightGBM usa algoritmos baseados em histograma [4, 5, 6] , que agrupam valores de recursos cont√≠nuos (atributos) em compartimentos discretos. Isso acelera o treinamento e reduz o uso de mem√≥ria. As vantagens dos algoritmos baseados em histogramas incluem o seguinte:\n",
        "\n",
        "    Custo reduzido de c√°lculo do ganho para cada divis√£o\n",
        "\n",
        "        Algoritmos baseados em pr√©-ordena√ß√£o t√™m complexidade de tempoO(#data)\n",
        "\n",
        "        Calcular o histograma tem complexidade de tempo O(#data), mas isso envolve apenas uma opera√ß√£o de soma r√°pida. Uma vez que o histograma √© constru√≠do, um algoritmo baseado em histograma tem complexidade O(#bins)de tempo e #bins√© muito menor que #data.\n",
        "\n",
        "    Use a subtra√ß√£o do histograma para acelerar ainda mais\n",
        "\n",
        "        Para obter os histogramas de uma folha em uma √°rvore bin√°ria, use a subtra√ß√£o do histograma de seu pai e seu vizinho\n",
        "\n",
        "        Portanto, ele precisa construir histogramas para apenas uma folha (com menor #dataque sua vizinha). Ele ent√£o pode obter histogramas de seu vizinho por subtra√ß√£o de histograma com pequeno custo ( O(#bins))\n",
        "\n",
        "    Reduza o uso de mem√≥ria\n",
        "\n",
        "        Substitui valores cont√≠nuos por compartimentos discretos. Se #binsfor pequeno, pode usar o tipo de dados pequeno, por exemplo, uint8_t, para armazenar dados de treinamento\n",
        "\n",
        "        N√£o h√° necessidade de armazenar informa√ß√µes adicionais para valores de recursos de pr√©-classifica√ß√£o\n",
        "\n",
        "    Reduza o custo de comunica√ß√£o para aprendizado distribu√≠do\n",
        "\n"
      ],
      "metadata": {
        "id": "Spqph2LUhi7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suporte a variaveis categ√≥ricas sem fazer one hot\n",
        "* categorical_feature"
      ],
      "metadata": {
        "id": "6_-WjnnrgBlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Par√¢metros\n",
        "num_leaves, default =31, type = int, aliases:num_leaf,max_leaves,max_leaf,max_leaf_nodes, restri√ß√µes:1 < num_leaves <= 131072\n",
        "\n",
        "    n√∫mero m√°ximo de folhas em uma √°rvore\n",
        "<hr>\n",
        "\n",
        "tree_learner , default =serial, type = enum, op√ß√µes:serial,feature,data,voting, aliases:tree,tree_type,tree_learner_type\n",
        "\n",
        "    serial, aprendizado de √°rvore de m√°quina √∫nica\n",
        "\n",
        "    feature, recurso de aprendizado de √°rvore paralela, aliases:feature_parallel\n",
        "\n",
        "    data, aprendiz de √°rvore paralela de dados, aliases:data_parallel\n",
        "\n",
        "    voting, aluno de √°rvore paralela de vota√ß√£o, aliases:voting_parallel\n",
        "\n",
        "    consulte o Guia de Aprendizagem Distribu√≠da para obter mais detalhes - https://lightgbm-readthedocs-io.translate.goog/en/v3.3.2/Parallel-Learning-Guide.html?_x_tr_sl=en&_x_tr_tl=pt&_x_tr_hl=pt-BR&_x_tr_pto=sc\n",
        "<hr>\n",
        "\n",
        "num_threads üîóÔ∏é , default =0, type = int, aliases:num_thread,nthread,nthreads,n_jobs\n",
        "\n",
        "    n√∫mero de threads para LightGBM\n",
        "\n",
        "    0significa o n√∫mero padr√£o de threads no OpenMP\n",
        "\n",
        "    para a melhor velocidade, defina isso para o n√∫mero de n√∫cleos de CPU reais , n√£o o n√∫mero de threads (a maioria das CPUs usa hyper-threading para gerar 2 threads por n√∫cleo de CPU)\n",
        "\n",
        "    n√£o defina muito grande se seu conjunto de dados for pequeno (por exemplo, n√£o use 64 threads para um conjunto de dados com 10.000 linhas)\n",
        "\n",
        "    esteja ciente de que um gerenciador de tarefas ou qualquer ferramenta de monitoramento de CPU semelhante pode relatar que os n√∫cleos n√£o est√£o sendo totalmente utilizados. Isto √© normal\n",
        "\n",
        "    para aprendizado distribu√≠do, n√£o use todos os n√∫cleos da CPU, pois isso causar√° um desempenho ruim para a comunica√ß√£o da rede\n",
        "\n",
        "    Nota : por favor , n√£o altere isso durante o treinamento, especialmente ao executar v√°rios trabalhos simultaneamente por pacotes externos, caso contr√°rio, poder√° causar erros indesej√°veis\n",
        "\n",
        "\n",
        "\n",
        "device_type üîóÔ∏é , default =cpu, type = enum, op√ß√µes:cpu,gpu,cuda, aliases:device\n",
        "\n",
        "    dispositivo para o aprendizado em √°rvore, voc√™ pode usar a GPU para obter o aprendizado mais r√°pido\n",
        "\n",
        "    Nota : recomenda-se usar o menor max_bin(por exemplo, 63) para obter a melhor velocidade\n",
        "\n",
        "    Nota : para a velocidade mais r√°pida, a GPU usa o ponto flutuante de 32 bits para resumir por padr√£o, portanto, isso pode afetar a precis√£o de algumas tarefas. Voc√™ pode configurar gpu_use_dp=truepara habilitar o ponto flutuante de 64 bits, mas isso retardar√° o treinamento\n",
        "\n",
        "    Nota : consulte o Guia de instala√ß√£o para construir LightGBM com suporte a GPU\n",
        "\n",
        "<hr>\n",
        "seed üîóÔ∏é , default =None, type = int, aliases:random_seed,random_state\n",
        "\n",
        "    esta semente √© usada para gerar outras sementes, por exemplo data_random_seed, feature_fraction_seed, etc.\n",
        "\n",
        "    por padr√£o, esta semente n√£o √© usada em favor dos valores padr√£o de outras sementes\n",
        "\n",
        "    esta semente tem prioridade menor em compara√ß√£o com outras sementes, o que significa que ela ser√° substitu√≠da, se voc√™ definir outras sementes explicitamente\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbHHxnRln5jh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hiperpar√£metros de Controle de Aprendizagem\n",
        "\n",
        "<hr>\n",
        "max_depth üîóÔ∏é , padr√£o =-1, tipo = int\n",
        "\n",
        "    limitar a profundidade m√°xima para o modelo de √°rvore. Isso √© usado para lidar com o ajuste excessivo quando #data√© pequeno. A √°rvore ainda cresce em folha\n",
        "\n",
        "    <= 0significa sem limite\n",
        "\n",
        "\n",
        "<hr>\n",
        "min_data_in_leaf üîóÔ∏é , default =20, type = int, aliases:min_data_per_leaf,min_data,min_child_samples,min_samples_leaf, restri√ß√µes:min_data_in_leaf >= 0\n",
        "\n",
        "    n√∫mero m√≠nimo de dados em uma folha. Pode ser usado para lidar com sobre-ajuste\n",
        "\n",
        "    Nota : esta √© uma aproxima√ß√£o baseada no Hessian, ent√£o ocasionalmente voc√™ pode observar divis√µes que produzem n√≥s folha que t√™m menos do que este n√∫mero de observa√ß√µes\n",
        "\n",
        "\n",
        "<hr>\n",
        "<b>Desbalanceamento</b>\n",
        "\n",
        "pos_bagging_fraction üîóÔ∏é , default =1.0, type = double, aliases:pos_sub_row,pos_subsample,pos_bagging, restri√ß√µes:0.0 < pos_bagging_fraction <= 1.0\n",
        "\n",
        "    usado apenas em binaryaplica√ß√µes\n",
        "\n",
        "    usado para o problema de classifica√ß√£o bin√°ria desequilibrada, amostrar√° aleatoriamente amostras positivas em ensacamento#pos_samples * pos_bagging_fraction\n",
        "\n",
        "    deve ser usado em conjunto comneg_bagging_fraction\n",
        "\n",
        "    defina isso 1.0para desabilitar\n",
        "\n",
        "    Nota : para habilitar isso, voc√™ precisa definir bagging_freqe neg_bagging_fractiontamb√©m\n",
        "\n",
        "    Nota : se ambos pos_bagging_fractione neg_bagging_fractionestiverem definidos como 1.0, o ensacamento balanceado ser√° desabilitado\n",
        "\n",
        "    Nota : se o ensacamento balanceado estiver habilitado, bagging_fractionser√° ignorado\n",
        "\n",
        "<hr>\n",
        "neg_bagging_fraction üîóÔ∏é , default =1.0, type = double, aliases:neg_sub_row,neg_subsample,neg_bagging, restri√ß√µes:0.0 < neg_bagging_fraction <= 1.0\n",
        "\n",
        "    usado apenas em binaryaplica√ß√µes\n",
        "\n",
        "    usado para o problema de classifica√ß√£o bin√°ria desequilibrada, amostrar√° aleatoriamente amostras negativas no ensacamento#neg_samples * neg_bagging_fraction\n",
        "\n",
        "    deve ser usado em conjunto compos_bagging_fraction\n",
        "\n",
        "    defina isso 1.0para desabilitar\n",
        "\n",
        "    Nota : para habilitar isso, voc√™ precisa definir bagging_freqe pos_bagging_fractiontamb√©m\n",
        "\n",
        "    Nota : se ambos pos_bagging_fractione neg_bagging_fractionestiverem definidos como 1.0, o ensacamento balanceado ser√° desabilitado\n",
        "\n",
        "    Nota : se o ensacamento balanceado estiver habilitado, bagging_fractionser√° ignorado\n",
        "\n",
        "\n",
        "<hr>\n",
        "bagging_freq üîóÔ∏é , default =0, type = int, aliases:subsample_freq\n",
        "\n",
        "    frequ√™ncia de ensacamento\n",
        "\n",
        "    0significa desabilitar o ensacamento; ksignifica realizar o ensacamento a cada kitera√ß√£o. A cada k-th itera√ß√£o, o LightGBM selecionar√° aleatoriamente os dados a serem usados ‚Äã‚Äãnas pr√≥ximas itera√ß√µesbagging_fraction * 100 %k\n",
        "\n",
        "    Nota : para habilitar o ensacamento, bagging_fractiondeve ser configurado para valor menor que 1.0tamb√©m\n",
        "\n",
        "\n",
        "<hr>\n",
        "<hr>\n",
        "early_stopping_round üîóÔ∏é , default =0, type = int, aliases:early_stopping_rounds,early_stopping,n_iter_no_change\n",
        "\n",
        "    ir√° parar de treinar se uma m√©trica de um dado de valida√ß√£o n√£o melhorar nas √∫ltimas early_stopping_roundrodadas\n",
        "\n",
        "    <= 0significa desabilitar\n",
        "\n",
        "    pode ser usado para acelerar o treinamento\n",
        "\n",
        "\n",
        "<hr>\n",
        "extra_trees üîóÔ∏é , default =false, type = bool, aliases:extra_tree\n",
        "\n",
        "    use √°rvores extremamente aleat√≥rias\n",
        "\n",
        "    se definido como true, ao avaliar as divis√µes de n√≥s, o LightGBM verificar√° apenas um limite escolhido aleatoriamente para cada recurso\n",
        "\n",
        "    pode ser usado para acelerar o treinamento\n",
        "\n",
        "    pode ser usado para lidar com excesso de ajuste\n",
        "\n",
        "<hr>\n",
        "path_smooth üîóÔ∏é , default =0, type = double, restri√ß√µes:path_smooth >=  0.0\n",
        "\n",
        "    controla a suaviza√ß√£o aplicada aos n√≥s da √°rvore\n",
        "\n",
        "    ajuda a evitar overfitting em folhas com poucas amostras\n",
        "\n",
        "    se definido como zero, nenhuma suaviza√ß√£o √© aplicada\n",
        "\n",
        "    se ent√£o deve ser pelo menospath_smooth > 0min_data_in_leaf2\n",
        "\n",
        "    valores maiores d√£o uma regulariza√ß√£o mais forte\n",
        "\n",
        "        o peso de cada n√≥ √© , onde √© o n√∫mero de amostras no n√≥, √© o peso ideal do n√≥ para minimizar a perda (aproximadamente ), e √© o peso do n√≥ pai(n / path_smooth) * w + w_p / (n / path_smooth + 1)nw-sum_gradients / sum_hessiansw_p\n",
        "\n",
        "        observe que a pr√≥pria sa√≠da pai w_ptem suaviza√ß√£o aplicada, a menos que seja o n√≥ raiz, para que o efeito de suaviza√ß√£o se acumule com a profundidade da √°rvore\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rElKlXt_o2fC"
      }
    }
  ]
}